package utils_test

import (
	"testing"

	"github.com/nyaruka/goflow/utils"

	"github.com/stretchr/testify/assert"
)

func TestSnakify(t *testing.T) {
	var snakeTests = []struct {
		input    string
		expected string
	}{
		{"Hello World", "hello_world"},
		{"hello_world", "hello_world"},
		{"hello-world", "hello_world"},
		{"_Hello World", "_hello_world"},
		{"   Hello World    ", "hello_world"},
		{"hiðŸ˜€ðŸ˜ƒðŸ˜„ðŸ˜there", "hi_there"},
		{"æ˜¨å¤œã®ã‚³", "æ˜¨å¤œã®ã‚³"},
		{"this@isn't@email", "this_isn_t_email"},
	}

	for _, test := range snakeTests {
		assert.Equal(t, test.expected, utils.Snakify(test.input), "unexpected result snakifying '%s'", test.input)
	}
}

func TestTokenizeString(t *testing.T) {
	tokenizerTests := []struct {
		text   string
		result []string
	}{
		{" one ", []string{"one"}},
		{"one   two three", []string{"one", "two", "three"}},
		{"one.two.three", []string{"one", "two", "three"}},
		{"O'Grady can't foo_bar", []string{"O'Grady", "can't", "foo_bar"}}, // single quotes and underscores don't split tokens
		{"Ã¶ne.Î²Î®Ï„Î±a.thÃ©", []string{"Ã¶ne", "Î²Î®Ï„Î±a", "thÃ©"}},                 // non-latin letters allowed in tokens
		{"ÙˆØ§Ø­Ø¯ Ø§Ø«Ù†ÙŠÙ† Ø«Ù„Ø§Ø«Ø©", []string{"ÙˆØ§Ø­Ø¯", "Ø§Ø«Ù†ÙŠÙ†", "Ø«Ù„Ø§Ø«Ø©"}},           // RTL scripts
		{"  \t\none(two!*@three ", []string{"one", "two", "three"}},        // other punctuation ignored
		{"spend$Â£â‚¬â‚ â‚£â‚ª", []string{"spend", "$", "Â£", "â‚¬", "â‚ ", "â‚£", "â‚ª"}},   // currency symbols treated as individual tokens
		{"math+=Ã—Ã·âˆšâˆŠ", []string{"math", "+", "=", "Ã—", "Ã·", "âˆš", "âˆŠ"}},     // math symbols treated as individual tokens
		{"emojiðŸ˜„ðŸ¥ðŸ‘ªðŸ‘°ðŸ˜ŸðŸ§Ÿ", []string{"emoji", "ðŸ˜„", "ðŸ¥", "ðŸ‘ª", "ðŸ‘°", "ðŸ˜Ÿ", "ðŸ§Ÿ"}},   // emojis treated as individual tokens
		{"ðŸ‘ðŸ¿ ðŸ‘¨ðŸ¼", []string{"ðŸ‘", "ðŸ¿", "ðŸ‘¨", "ðŸ¼"}},                            // tone modifiers treated as individual tokens
		{"â„¹ â„¹ï¸", []string{"â„¹", "â„¹ï¸"}},                                      // variation selectors ignored
		{"à¸¢à¸à¹€à¸¥à¸´à¸ sasa", []string{"à¸¢à¸à¹€à¸¥à¸´à¸", "sasa"}},                        // Thai word means Cancelled
		{"à¦¬à¦¾à¦¤à¦¿à¦² sasa", []string{"à¦¬à¦¾à¦¤à¦¿à¦²", "sasa"}},                          // Bangla word means Cancel
		{"á€‘á€½á€€á€ºá€žá€½á€¬á€¸ sasa", []string{"á€‘á€½á€€á€ºá€žá€½á€¬á€¸", "sasa"}},                    // Burmese word means exit
	}
	for _, test := range tokenizerTests {
		assert.Equal(t, test.result, utils.TokenizeString(test.text), "unexpected result tokenizing '%s'", test.text)
	}
}

func TestTokenizeStringByChars(t *testing.T) {
	tokenizerTests := []struct {
		text   string
		chars  string
		result []string
	}{
		{"one   two three", " ", []string{"one", "two", "three"}},
		{"Jim O'Grady", " ", []string{"Jim", "O'Grady"}},
		{"one.Î²Î®Ï„Î±a/three", "./", []string{"one", "Î²Î®Ï„Î±a", "three"}},
		{"oneðŸ˜„three", "ðŸ˜„", []string{"one", "three"}},
		{"  one.two.*@three ", " .*@", []string{"one", "two", "three"}},
		{" one ", " ", []string{"one"}},
	}
	for _, test := range tokenizerTests {
		assert.Equal(t, test.result, utils.TokenizeStringByChars(test.text, test.chars), "unexpected result tokenizing '%s'", test.text)
	}
}

func TestPrefixOverlap(t *testing.T) {
	assert.Equal(t, 0, utils.PrefixOverlap("", ""))
	assert.Equal(t, 0, utils.PrefixOverlap("abc", ""))
	assert.Equal(t, 0, utils.PrefixOverlap("", "abc"))
	assert.Equal(t, 0, utils.PrefixOverlap("a", "x"))
	assert.Equal(t, 1, utils.PrefixOverlap("x", "x"))
	assert.Equal(t, 2, utils.PrefixOverlap("xya", "xyz"))
	assert.Equal(t, 2, utils.PrefixOverlap("ðŸ˜„ðŸ˜ŸðŸ‘¨ðŸ¼", "ðŸ˜„ðŸ˜ŸðŸ‘°"))
	assert.Equal(t, 4, utils.PrefixOverlap("25078", "25073254252"))
}

func TestStringSlices(t *testing.T) {
	assert.Equal(t, []string{"he", "hello", "world"}, utils.StringSlices("hello world", []int{0, 2, 0, 5, 6, 11}))
}

func TestStringSliceContains(t *testing.T) {
	assert.False(t, utils.StringSliceContains(nil, "a", true))
	assert.False(t, utils.StringSliceContains([]string{}, "a", true))
	assert.False(t, utils.StringSliceContains([]string{"b", "c"}, "a", true))
	assert.True(t, utils.StringSliceContains([]string{"b", "a", "c"}, "a", true))
	assert.False(t, utils.StringSliceContains([]string{"b", "a", "c"}, "A", true))
	assert.True(t, utils.StringSliceContains([]string{"b", "a", "c"}, "A", false))
}

func TestIndent(t *testing.T) {
	assert.Equal(t, "", utils.Indent("", "  "))
	assert.Equal(t, "  x", utils.Indent("x", "  "))
	assert.Equal(t, "  x\n  y", utils.Indent("x\ny", "  "))
	assert.Equal(t, "  x\n\n  y", utils.Indent("x\n\ny", "  "))
	assert.Equal(t, ">>>x", utils.Indent("x", ">>>"))
}

func TestStringSet(t *testing.T) {
	set := utils.NewStringSet(0)
	set.Add("x")
	set.Add("x")
	assert.True(t, set.Contains("x"))
	assert.False(t, set.Contains("y"))
	assert.Equal(t, []string{"x"}, set.Slice())
}
